{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pykonal\n",
    "import seispy\n",
    "\n",
    "EARTH_RADIUS = 6371.\n",
    "DTYPE_REAL = np.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "cimport numpy as np\n",
    "\n",
    "\n",
    "ctypedef np.float64_t _REAL_t\n",
    "\n",
    "EARTH_RADIUS = 6371.\n",
    "DTYPE_REAL = np.float64\n",
    "\n",
    "def geo2sph(arr):\n",
    "    \"\"\"\n",
    "    Map Geographical coordinates to spherical coordinates.\n",
    "    \"\"\"\n",
    "    geo = np.array(arr, dtype=DTYPE_REAL)\n",
    "    sph = np.empty_like(geo)\n",
    "    sph[..., 0] = EARTH_RADIUS - geo[..., 2]\n",
    "    sph[..., 1] = np.pi / 2 - np.radians(geo[..., 0])\n",
    "    sph[..., 2] = np.radians(geo[..., 1])\n",
    "    return (sph)\n",
    "\n",
    "\n",
    "def sph2geo(arr):\n",
    "    \"\"\"\n",
    "    Map spherical coordinates to geographic coordinates.\n",
    "    \"\"\"\n",
    "    sph = np.array(arr, dtype=DTYPE_REAL)\n",
    "    geo = np.empty_like(sph)\n",
    "    geo[..., 0] = np.degrees(np.pi / 2 - sph[..., 1])\n",
    "    geo[..., 1] = np.degrees(sph[..., 2])\n",
    "    geo[..., 2] = EARTH_RADIUS - sph[..., 0]\n",
    "    return (geo)\n",
    "\n",
    "\n",
    "cdef class EQLocator(object):\n",
    "    cdef dict _arrivals\n",
    "    cdef dict _tt_calculators\n",
    "    cdef _REAL_t[:,:,:,:] _grid\n",
    "    cdef tuple _bounds\n",
    "    cdef dict _priors\n",
    "    \n",
    "    def __init__(self, arrivals, tt_calculators, grid):\n",
    "        self._arrivals = {key: arrivals[key] for key in tt_calculators}\n",
    "        self._tt_calculators = tt_calculators\n",
    "        self._grid = grid\n",
    "    \n",
    "    @property\n",
    "    def arrivals(self):\n",
    "        return (self._arrivals)\n",
    "    \n",
    "    @arrivals.setter\n",
    "    def arrivals(self, value):\n",
    "        self._arrivals = value\n",
    "    \n",
    "    @property\n",
    "    def grid(self):\n",
    "        return (np.asarray(self._grid))\n",
    "    \n",
    "    @grid.setter\n",
    "    def grid(self, value):\n",
    "        self._grid = value\n",
    "        \n",
    "    @property\n",
    "    def tt_calculators(self):\n",
    "        return (self._tt_calculators)\n",
    "    \n",
    "    @tt_calculators.setter\n",
    "    def tt_calculators(self, value):\n",
    "        self._tt_calculators = value\n",
    "        \n",
    "    cpdef initial_guess(self):\n",
    "        values = [self.arrivals[key]-self.tt_calculators[key].values for key in self.tt_calculators]\n",
    "        values = np.ma.masked_invalid(np.stack(values))\n",
    "        std = values.std(axis=0)\n",
    "        arg_min = np.argmin(std)\n",
    "        idx_min = np.unravel_index(arg_min, std.shape)\n",
    "        geo = sph2geo(self.grid[idx_min])\n",
    "        time = values.mean(axis=0)[idx_min]\n",
    "        return (np.array([*geo, time]))\n",
    "\n",
    "    cpdef cost(self, _REAL_t[:] hypocenter):\n",
    "        cdef tuple key\n",
    "        cdef _REAL_t csum, lat, lon, depth, time\n",
    "        lat = hypocenter[0]\n",
    "        lon = hypocenter[1]\n",
    "        depth = hypocenter[2]\n",
    "        time = hypocenter[3]\n",
    "        for key in self.arrivals:\n",
    "            sph_coords = geo2sph((lat, lon, depth, time))\n",
    "            tt_calculator = self.tt_calculators[key].value\n",
    "            csum += np.square(self.arrivals[key]-(time+tt_calculator(sph_coords)))\n",
    "        return (np.sqrt(csum/len(self.arrivals)))\n",
    "    \n",
    "    cpdef locate(self):\n",
    "        cdef _REAL_t[4] h0\n",
    "        h0 = self.initial_guess()\n",
    "        soln = scipy.optimize.differential_evolution(\n",
    "            self.cost,\n",
    "            ((h0[0]-0.1, h0[0]+0.1), (h0[1]-0.1, h0[1]+0.1), (0, 30), (h0[3]-5, h0[3]+5))\n",
    "        )\n",
    "        return (soln.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_farfield(vmodel):\n",
    "    \"\"\"\n",
    "    Initialize the far-field EikonalSolver with the given velocity model.\n",
    "    \"\"\"\n",
    "    far_field = pykonal.EikonalSolver(coord_sys='spherical')\n",
    "    far_field.vv.min_coords = vmodel.min_coords\n",
    "    far_field.vv.node_intervals = vmodel.node_intervals\n",
    "    far_field.vv.npts = vmodel.npts\n",
    "    far_field.vv.values = vmodel.values\n",
    "    return (far_field)\n",
    "\n",
    "def init_nearfield(far_field, origin):\n",
    "    \"\"\"\n",
    "    Initialize the near-field EikonalSolver.\n",
    "    :param origin: Station location in spherical coordinates.\n",
    "    :type origin: (float, float, float)\n",
    "    :return: Near-field EikonalSolver\n",
    "    :rtype: pykonal.EikonalSolver\n",
    "    \"\"\"\n",
    "    refinement_factor = 10\n",
    "    drho = far_field.vv.node_intervals[0] / refinement_factor\n",
    "    near_field = pykonal.EikonalSolver(coord_sys=\"spherical\")\n",
    "    near_field.vv.min_coords = drho, 0, 0\n",
    "    near_field.vv.node_intervals = drho, np.pi / 20, np.pi / 20\n",
    "    near_field.vv.npts = 100, 21, 40\n",
    "    nodes = near_field.vv.transform_coordinates(\"spherical\", origin)\n",
    "    near_field.vv.values = far_field.vv.resample(nodes.reshape(-1, 3)).reshape(near_field.vv.npts)\n",
    "    for it in range(near_field.tt.npts[1]):\n",
    "        for ip in range(near_field.tt.npts[2]):\n",
    "            idx = (0, it, ip)\n",
    "            vv = near_field.vv.values[idx]\n",
    "            if not np.isnan(vv):\n",
    "                near_field.tt.values[idx] = near_field.tt.nodes[idx + (0,)] / vv\n",
    "                near_field.is_far[idx] = False\n",
    "                near_field.close.push(*idx)\n",
    "    return (near_field)\n",
    "\n",
    "def compute_traveltime_lookup_table(origin, vmodel):\n",
    "    far_field = init_farfield(vmodel)\n",
    "    near_field = init_nearfield(far_field, origin)\n",
    "    near_field.solve()\n",
    "\n",
    "    # Compute the origin of the far-field coordinate system w.r.t. the\n",
    "    # near-field coordinate system.\n",
    "    origin = (origin[0], np.pi - origin[1], (origin[2] + np.pi) % (2*np.pi))\n",
    "    nodes = far_field.tt.transform_coordinates(\"spherical\", origin)    \n",
    "    # Determine which nodes of the far-field grid fall inside the\n",
    "    # bounds of the near-field grid.\n",
    "    nonzero_idx = np.nonzero(\n",
    "         (nodes[...,0] >= near_field.vv.min_coords[0])\n",
    "        &(nodes[...,0] <= near_field.vv.max_coords[0])\n",
    "        &(nodes[...,1] >= near_field.vv.min_coords[1])\n",
    "        &(nodes[...,1] <= near_field.vv.max_coords[1])\n",
    "        &(nodes[...,2] >= near_field.vv.min_coords[2])\n",
    "        &(nodes[...,2] <= near_field.vv.max_coords[2])\n",
    "    )\n",
    "    # Interpolate traveltimes from the near-field grid onto the \n",
    "    # far-field grid.\n",
    "    tt = near_field.tt.resample(nodes[nonzero_idx])\n",
    "    # Determine which of the interpolated values are NaNs.\n",
    "    nan_idx = np.isnan(tt)\n",
    "    # Drop the indices for NaNs.\n",
    "    nonzero_idx = tuple(nonzero_idx[i][~nan_idx] for i in range(3))\n",
    "    # Update the far-field traveltime grid with interpolated values.\n",
    "    far_field.tt.values[nonzero_idx] = near_field.tt.resample(nodes[nonzero_idx])\n",
    "    # Update the state variables for tracking the narrow band.\n",
    "    far_field.is_far[nonzero_idx] = False\n",
    "    nonzero_idx = np.stack(nonzero_idx)\n",
    "    for idx in range(nonzero_idx.shape[1]):\n",
    "        idx = tuple(nonzero_idx[:,idx])\n",
    "        far_field.close.push(*idx)\n",
    "    far_field.solve()\n",
    "    return (far_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = seispy.pandas.catalog.Catalog(\n",
    "    \"/home/malcolmw/google_drive/malcolm.white@usc.edu/data/events/malcolmw/SJFZ_catalog_2008-2016.h5\",\n",
    "    fmt=\"hdf5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(\"/home/malcolmw/google_drive/malcolm.white@usc.edu/data/velocity/White_et_al_2019a/White_et_al_2019a.regular.npz\") as npz:\n",
    "    vp = pykonal.field.ScalarField3D(coord_sys=\"spherical\")\n",
    "    vs = pykonal.field.ScalarField3D(coord_sys=\"spherical\")\n",
    "    vp.min_coords = vs.min_coords = npz[\"grid_parameters\"][:3]\n",
    "    vp.node_intervals = vs.node_intervals = npz[\"grid_parameters\"][3:6]\n",
    "    vp.npts = vs.npts = npz[\"grid_parameters\"][6:]\n",
    "    vp.values = npz[\"vp\"]\n",
    "    vs.values = npz[\"vs\"]\n",
    "    \n",
    "# Resample the velocity model (17, 32, 32) --> (64, 128, 128)\n",
    "rho_min, theta_min, phi_min = vp.min_coords\n",
    "rho_max, theta_max, phi_max = vp.max_coords\n",
    "nrho, ntheta, nphi = 64, 128, 128\n",
    "\n",
    "drho = (rho_max - rho_min) / (nrho - 1)\n",
    "rho = np.linspace(rho_min, rho_max, nrho)\n",
    "\n",
    "dtheta = (theta_max - theta_min) / (ntheta - 1)\n",
    "theta = np.linspace(theta_min, theta_max, ntheta)\n",
    "\n",
    "dphi = (phi_max - phi_min) / (nphi - 1)\n",
    "phi = np.linspace(phi_min, phi_max, nphi)\n",
    "\n",
    "rtp = np.moveaxis(\n",
    "    np.stack(np.meshgrid(rho, theta, phi, indexing=\"ij\")),\n",
    "    0, \n",
    "    -1\n",
    ")\n",
    "vp_new = vp.resample(rtp.reshape(-1, 3)).reshape(rtp.shape[:-1])\n",
    "vs_new = vs.resample(rtp.reshape(-1, 3)).reshape(rtp.shape[:-1])\n",
    "\n",
    "vp = pykonal.field.ScalarField3D(coord_sys=\"spherical\")\n",
    "vs = pykonal.field.ScalarField3D(coord_sys=\"spherical\")\n",
    "vp.min_coords = vs.min_coords = rho_min, theta_min, phi_min\n",
    "vp.node_intervals = vs.node_intervals = drho, dtheta, dphi\n",
    "vp.npts = vs.npts = nrho, ntheta, nphi\n",
    "vp.values = vp_new\n",
    "vs.values = vs_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_dataframe = db[\"site\"][\n",
    "    [\"sta\", \"lat\", \"lon\", \"elev\"]\n",
    "].drop_duplicates(\n",
    "    \"sta\"\n",
    ").merge(\n",
    "    db[\"snetsta\"][\n",
    "        [\"snet\", \"sta\"]\n",
    "    ].drop_duplicates(\n",
    "        \"sta\"\n",
    "    ),\n",
    "    on=\"sta\"\n",
    ")\n",
    "stations_dataframe[\"station_id\"] = stations_dataframe[\"snet\"] + \".\" + stations_dataframe[\"sta\"]\n",
    "\n",
    "arrivals_dataframe = db[\"arrival\"][\n",
    "    [\"sta\", \"time\", \"arid\"]\n",
    "].merge(\n",
    "    db[\"assoc\"][\n",
    "        [\"arid\", \"orid\", \"phase\"]\n",
    "    ],\n",
    "    on=\"arid\"\n",
    ").merge(\n",
    "    stations_dataframe[[\"sta\", \"station_id\"]],\n",
    "    on=\"sta\"\n",
    ").sort_values(\n",
    "    \"orid\"\n",
    ").set_index(\n",
    "    \"orid\"\n",
    ")[\n",
    "    [\"station_id\", \"phase\", \"time\", \"arid\"]\n",
    "]\n",
    "\n",
    "stations_dataframe[\"depth\"] = -stations_dataframe[\"elev\"]\n",
    "stations_dataframe = stations_dataframe[\n",
    "    [\"station_id\", \"lat\", \"lon\", \"depth\"]\n",
    "].set_index(\n",
    "    \"station_id\"\n",
    ")\n",
    "stations_dataframe = stations_dataframe[\n",
    "    stations_dataframe.index.isin(arrivals_dataframe[\"station_id\"].unique())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute traveltime-lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(args, vp=vp, vs=vs):\n",
    "    station_id, coords = args[0], geo2sph(args[1].values)\n",
    "    print(station_id)\n",
    "    solver = compute_traveltime_lookup_table(coords, vp)\n",
    "    solver.tt.savez(f\"/home/malcolmw/scratch/traveltimes/{station_id}.P.npz\")\n",
    "    solver = compute_traveltime_lookup_table(coords, vs)\n",
    "    solver.tt.savez(f\"/home/malcolmw/scratch/traveltimes/{station_id}.S.npz\")\n",
    "    \n",
    "with mp.Pool(8) as pool:\n",
    "    pool.map(target, stations_dataframe.iterrows())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locate events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for origin_id in np.random.choice(arrivals_dataframe.index.unique(), size=10):\n",
    "    arrivals = arrivals_dataframe.loc[origin_id].set_index([\"station_id\", \"phase\"]).to_dict()[\"time\"]\n",
    "    print(origin_id, len(arrivals))\n",
    "    tt_calculators = {\n",
    "        key: pykonal.field.load(f\"/home/malcolmw/scratch/traveltimes/{key[0]}.{key[1]}.npz\") for key in arrivals\n",
    "    }\n",
    "    locator = EQLocator(\n",
    "        arrivals=arrivals,\n",
    "        tt_calculators=tt_calculators,\n",
    "        grid=vp.nodes\n",
    "    )\n",
    "    print(locator.locate())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
