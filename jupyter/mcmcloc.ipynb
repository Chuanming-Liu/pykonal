{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pykonal\n",
    "import scipy.stats\n",
    "import seispy\n",
    "\n",
    "EARTH_RADIUS = 6371.\n",
    "\n",
    "MEAN_P_RESIDUAL = 0.\n",
    "STD_P_RESIDUAL = 0.15\n",
    "MEAN_S_RESIDUAL = 0.0\n",
    "STD_S_RESIDUAL = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = seispy.pandas.catalog.Catalog(\n",
    "    \"/home/malcolmw/google_drive/malcolm.white@usc.edu/data/events/malcolmw/SJFZ_catalog_2008-2016.h5\",\n",
    "    fmt=\"hdf5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event = db[\"origin\"].merge(\n",
    "    db[\"origerr\"][[\"orid\", \"smajax\", \"sdepth\"]],\n",
    "    on=\"orid\"\n",
    ")\n",
    "df_event = df_event[\n",
    "     (df_event[\"algorithm\"] == \"GrowClust\")\n",
    "    |(\n",
    "         (df_event[\"algorithm\"] == \"NonLinLoc\")\n",
    "        &(df_event[\"smajax\"] < 3)\n",
    "        &(df_event[\"sdepth\"] < 3)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db[\"assoc\"][[\"arid\", \"orid\", \"sta\", \"phase\"]][\n",
    "    db[\"assoc\"][\"orid\"].isin(df_event[\"orid\"])\n",
    "].merge(\n",
    "    df_event[[\"orid\", \"evid\"]],\n",
    "    on=\"orid\"\n",
    ").merge(\n",
    "    db[\"arrival\"][[\"arid\", \"time\"]],\n",
    "    on=\"arid\"\n",
    ").merge(\n",
    "    db[\"snetsta\"][[\"snet\", \"sta\"]].drop_duplicates(\"sta\"),\n",
    "    on=\"sta\"\n",
    ")\n",
    "df[\"station_id\"] = df[\"snet\"] + \".\" + df[\"sta\"]\n",
    "df = df.drop(\n",
    "    columns=[\"arid\", \"orid\", \"snet\", \"sta\"]\n",
    ").sort_values(\n",
    "    [\"evid\", \"time\"]\n",
    ").set_index(\"evid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo2sph(geo):\n",
    "    geo = np.array(geo, dtype=np.float64)\n",
    "    sph = np.empty_like(geo)\n",
    "    sph[...,0] = EARTH_RADIUS - geo[...,2]\n",
    "    sph[...,1] = np.radians(90 - geo[...,0])\n",
    "    sph[...,2] = np.radians(geo[...,1])\n",
    "    return (sph)\n",
    "\n",
    "def sph2geo(sph):\n",
    "    sph = np.array(sph, dtype=np.float64)\n",
    "    geo = np.empty_like(sph)\n",
    "    geo[...,0] = np.degrees(np.pi/2 - sph[...,1])\n",
    "    geo[...,1] = np.degrees(sph[...,2])\n",
    "    geo[...,2] = EARTH_RADIUS - sph[...,0]\n",
    "    return (geo)\n",
    "\n",
    "\n",
    "def likelihood(model, data, priors, interpolators):\n",
    "    \"\"\"\n",
    "    Return the likelihood of the model given data and priors.\n",
    "    \n",
    "    :param model: lat, lon, depth, time coordinates of hypocenter.\n",
    "    :type model: Array-like of floats.\n",
    "    :param data: Station ID, phase, arrival time triplets for observed data.\n",
    "    :type data: tuple(str, str, float)\n",
    "    :param priors: Empirical residual PDFs in dict with (station ID, phase) keys. Values should be scipy.stats.rv_continuous.pdf or similar.\n",
    "    :type priors: dict\n",
    "    :param network: Station locations in dict where key is station ID and values are tuples with lat, lon, depth coordinates.\n",
    "    \"\"\"\n",
    "    data[\"key\"] = list(zip(data[\"station_id\"], data[\"phase\"]))\n",
    "    data = data[data[\"key\"].isin(interpolators)]\n",
    "    return (\n",
    "        np.prod([\n",
    "            priors[row[\"phase\"]](row[\"time\"]-(model[3] + interpolators[(row[\"station_id\"], row[\"phase\"])](geo2sph(model[:3]))))\n",
    "            for idx, row in data.iterrows()\n",
    "        ])\n",
    "    )\n",
    "\n",
    "\n",
    "def load_interpolator_from_file(filename):\n",
    "    try:\n",
    "        npz = np.load(filename)\n",
    "        grid = pykonal.Grid3D(coord_sys=\"spherical\")\n",
    "        grid.min_coords = npz[\"min_coords\"]\n",
    "        grid.node_intervals = npz[\"node_intervals\"]\n",
    "        grid.npts = npz[\"npts\"]\n",
    "        field = npz[\"uu\"]\n",
    "    finally:\n",
    "        npz.close()\n",
    "    return (pykonal.LinearInterpolator3D(grid, field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tti = load_interpolator_from_file(\"/home/malcolmw/scratch/traveltimes_HK1D/AZ.CRY.P.npz\")\n",
    "grid = pykonal.Grid3D(coord_sys=\"spherical\")\n",
    "grid.min_coords = tti.min_coords\n",
    "grid.node_intervals = tti.node_intervals\n",
    "grid.npts = tti.npts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = dict(\n",
    "    P=scipy.stats.norm(MEAN_P_RESIDUAL, STD_P_RESIDUAL).pdf,\n",
    "    S=scipy.stats.norm(MEAN_S_RESIDUAL, STD_S_RESIDUAL).pdf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\mathbf{m}$ and $\\mathbf{d}$ be vectors comprising a set of model parameters and observed data, respectively. Bayes theorem states\n",
    "\n",
    "\\begin{equation}\n",
    "    P\\left(\\mathbf{m}\\;\\middle|\\;\\mathbf{d}\\right) = \\frac{\n",
    "        P\\left(\\mathbf{d}\\;\\middle|\\;\\mathbf{m}\\right)P\\left(\\mathbf{m}\\right)\n",
    "    }{\n",
    "        P\\left(\\mathbf{d}\\right)\n",
    "    }.\n",
    "\\end{equation}\n",
    "\n",
    "In the case of locating earthquakes, $\\mathbf{m}=\\mathbf{h_0}=\\left[\\rho_0, \\theta_0, \\phi_0, t_0\\right]$ is the vector of hypocenter parameters and $\\mathbf{d}$ is a vector of observed phase-arrival times. The left hand side is known as the *posterior* probability, and represents the probability that any particular model underlies the oberved data. Locating an earthquake is tantamount to determining the model that most probably underlies the observed data.\n",
    "\n",
    "The denominator of the right hand side is known as the *evidence*. Because the evidence for an earthquake is constant and we are only interested in the relative maximum of the left hand side, we can safely ignore it as it plays the role of a scaling constant. \n",
    "\n",
    "The first term of numerator on the right hand side, $P\\left(\\textbf{d}\\;\\middle|\\;\\textbf{m}\\right)$, represents our knowledge of how the data are related to the model---i.e., for a given model, what is the probability of observing the data that was observed---and is known as the *prior* probability. \n",
    "\n",
    "Finally, the second term of the numerator on the right hand side, $P\\left(\\textbf{m}\\right)$ is the probability of the model taking on a particular set of parameters. A priori knowledge of the distribution of model parameters can be encoded here, or one can plead ignorance and simply assign all possible combinations of parameters equal probability, which is equivalent to setting $P\\left(\\textbf{m}\\right)$ equal to a uniform distribution.\n",
    "\n",
    "In the end, we have\n",
    "\\begin{equation}\n",
    "    P\\left(\\mathbf{h}_0\\;\\middle|\\;\\mathbf{d}\\right) \\propto P\\left(\\mathbf{d}\\;\\middle|\\;\\mathbf{h}_0\\right)\n",
    "\\end{equation}\n",
    "\n",
    "and we are interested in\n",
    "\\begin{equation}\n",
    "    \\underset{\\mathbf{h}_0}{argmax} \\left[P\\left(\\mathbf{h}_0\\;\\middle|\\;\\mathbf{d}\\right)\\right]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolators = dict()\n",
    "tt = []\n",
    "data = df.loc[8000025]\n",
    "for idx, row in data.iterrows():\n",
    "    station_id, phase = row[[\"station_id\", \"phase\"]]\n",
    "    try:\n",
    "        interpolators[(station_id, phase)] = load_interpolator_from_file(\n",
    "            f\"/home/malcolmw/scratch/traveltimes_HK1D/{station_id}.{phase}.npz\"\n",
    "        )\n",
    "        tt.append(row[\"time\"] - interpolators[(f\"{station_id}\", phase)].values)\n",
    "    except:\n",
    "        continue\n",
    "tt = np.stack(tt)\n",
    "idx_min = np.unravel_index(np.argmin(tt.std(axis=0)), tt.shape[1:])\n",
    "hypo0 = np.append(sph2geo(grid[idx_min]), tt.mean(axis=0)[idx_min]) # Initial hypocenter estimate\n",
    "likelihood(hypo0, data, priors, interpolators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_max, lon_min, depth_max = sph2geo(grid.min_coords)\n",
    "lat_min, lon_max, depth_min = sph2geo(grid.max_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sd_step_lat = np.degrees(grid.node_intervals[1]) / 20\n",
    "sd_step_lon = np.degrees(grid.node_intervals[2]) / 20\n",
    "sd_step_depth = grid.node_intervals[0] / 20\n",
    "sd_step_time = 0.05\n",
    "nstep = 500\n",
    "ntraces = 4\n",
    "\n",
    "lat_max, lon_min, depth_max = sph2geo(grid.min_coords)\n",
    "lat_min, lon_max, depth_min = sph2geo(grid.max_coords)\n",
    "\n",
    "traces = []\n",
    "map_hypos = []\n",
    "for itrace in range(ntraces):\n",
    "    while True:\n",
    "        hypo_prev = hypo0 + np.random.randn() * np.array([sd_step_lat, sd_step_lon, sd_step_depth, sd_step_time])\n",
    "        likeli_prev = likelihood(hypo_prev, data, priors, interpolators)\n",
    "        max_likeli, map_hypo = likeli_prev, hypo_prev\n",
    "        if likeli_prev > 0:\n",
    "            break\n",
    "    trace = np.array([])\n",
    "\n",
    "    for istep in range(nstep):\n",
    "        hypo_prop = np.empty(4)\n",
    "        while True:\n",
    "            lat_next = hypo_prev[0] + np.random.randn() * sd_step_lat\n",
    "            if lat_min <= lat_next <= lat_max:\n",
    "                hypo_prop[0] = lat_next\n",
    "                break\n",
    "        while True:\n",
    "            lon_next = hypo_prev[1] + np.random.randn() * sd_step_lon\n",
    "            if lon_min <= lon_next <= lon_max:\n",
    "                hypo_prop[1] = lon_next\n",
    "                break\n",
    "        while True:\n",
    "            depth_next = hypo_prev[2] + np.random.randn() * sd_step_depth\n",
    "            if depth_min <= depth_next <= depth_max:\n",
    "                hypo_prop[2] = depth_next\n",
    "                break\n",
    "        hypo_prop[3] = hypo_prev[3] + np.random.randn() * sd_step_time\n",
    "        likeli_prop = likelihood(hypo_prop, data, priors, interpolators)\n",
    "        likeli_prev = likelihood(hypo_prev, data, priors, interpolators)\n",
    "        rv = np.random.rand()\n",
    "        alpha = likeli_prop/likeli_prev\n",
    "        if alpha >= rv:\n",
    "            trace = np.append(trace, hypo_prop)\n",
    "            hypo_prev = hypo_prop\n",
    "            likeli_prev = likeli_prop\n",
    "            if likeli_prop > max_likeli:\n",
    "                max_likeli = likeli_prop\n",
    "                map_hypo = hypo_prop\n",
    "        else:\n",
    "            trace = np.append(trace, hypo_prev)\n",
    "    trace = trace.reshape(nstep, 4)\n",
    "    traces.append(trace)\n",
    "    map_hypos.append(map_hypo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig = plt.figure()\n",
    "ax0 = fig.add_subplot(2, 2, 1)\n",
    "ax1 = fig.add_subplot(2, 2, 2)\n",
    "ax2 = fig.add_subplot(2, 2, 3)\n",
    "ax3 = fig.add_subplot(2, 2, 4)\n",
    "for itrace in range(ntraces):\n",
    "    trace = traces[itrace]\n",
    "    map_hypo = map_hypos[itrace]\n",
    "#     counts, bins, patches = ax0.hist(trace[:,0], bins=50, density=True)\n",
    "    counts, bins = np.histogram(trace[:,0], bins=50, density=True)\n",
    "    kde = scipy.stats.gaussian_kde(trace[:,0])\n",
    "    ax0.plot(bins, kde(bins))\n",
    "    ax0.scatter(map_hypo[0], kde(map_hypo[0]), zorder=3)\n",
    "\n",
    "#     counts, bins, patches = ax1.hist(trace[:,1], bins=50, density=True)\n",
    "    counts, bins = np.histogram(trace[:,1], bins=50, density=True)\n",
    "    kde = scipy.stats.gaussian_kde(trace[:,1])\n",
    "    ax1.plot(bins, kde(bins))\n",
    "    ax1.scatter(map_hypo[1], kde(map_hypo[1]), zorder=3)\n",
    "\n",
    "#     counts, bins, patches = ax2.hist(trace[:,2], bins=50, density=True)\n",
    "    counts, bins = np.histogram(trace[:,2], bins=50, density=True)\n",
    "    kde = scipy.stats.gaussian_kde(trace[:,2])\n",
    "    ax2.plot(bins, kde(bins))\n",
    "    ax2.scatter(map_hypo[2], kde(map_hypo[2]), zorder=3)\n",
    "\n",
    "#     counts, bins, patches = ax3.hist(trace[:,3], bins=50, density=True)\n",
    "    counts, bins = np.histogram(trace[:,3], bins=50, density=True)\n",
    "    kde = scipy.stats.gaussian_kde(trace[:,3])\n",
    "    ax3.plot(bins, kde(bins))\n",
    "    ax3.scatter(map_hypo[3], kde(map_hypo[3]), zorder=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for itrace in range(len(traces)):\n",
    "    map_hypo = map_hypos[itrace]\n",
    "    trace = traces[itrace]\n",
    "    ax = fig.add_subplot(2, 2, itrace+1)\n",
    "    bm = seispy.mapping.Basemap(\n",
    "    #     continent_color=\"0.75\",\n",
    "        ax=ax\n",
    "    )\n",
    "    bm.scatter(trace[:,1], trace[:,0], s=1, linewidth=0, c=\"k\", zorder=2)\n",
    "#     bm.scatter(map_hypo[1], map_hypo[0], c=\"r\", zorder=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
